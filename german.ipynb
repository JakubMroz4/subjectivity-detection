{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c4db13-918e-46cf-a8d5-89285ad62b38",
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\Documents\\py_interpreter2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Import STOPWORDS from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string, re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c35f562f-c314-4a15-b279-f5b0b3ab3725",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/subtask-2-german/train_de.tsv\",sep='\\t')\n",
    "dev_data = pd.read_csv(\"data/subtask-2-german/dev_de.tsv\", sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "453ce330-db05-4ad1-b504-01003af28b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "795    0\n",
      "796    0\n",
      "797    0\n",
      "798    0\n",
      "799    0\n",
      "Name: label, Length: 800, dtype: int64\n",
      "0      0\n",
=======
      "0      1\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      1\n",
      "      ..\n",
      "825    1\n",
      "826    1\n",
      "827    1\n",
      "828    1\n",
      "829    1\n",
      "Name: label, Length: 830, dtype: int64\n",
      "0      1\n",
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
<<<<<<< HEAD
      "195    0\n",
      "196    1\n",
      "197    1\n",
      "198    1\n",
      "199    0\n",
      "Name: label, Length: 200, dtype: int64\n"
=======
      "214    1\n",
      "215    1\n",
      "216    1\n",
      "217    1\n",
      "218    0\n",
      "Name: label, Length: 219, dtype: int64\n"
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
     ]
    }
   ],
   "source": [
    "# Mapping label strings to integers\n",
    "label_map = {\"OBJ\": 0, \"SUBJ\": 1}\n",
    "train_data['label'] = train_data['label'].map(label_map)\n",
    "print(train_data['label'])\n",
    "\n",
    "dev_data['label'] = dev_data['label'].map(label_map)\n",
    "print(dev_data['label'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
   "id": "82bab64a-e3e9-4737-88f8-3069d51eea71",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['solved_conflict'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msolved_conflict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:5568\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5421\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5422\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5429\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5431\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5432\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5433\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5566\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5567\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5570\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5574\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5575\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5576\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4782\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4781\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4782\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4785\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4824\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4822\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4823\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4824\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4825\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4827\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4828\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7069\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7069\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7070\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7071\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['solved_conflict'] not found in axis\""
     ]
    }
   ],
   "source": [
    "train_data = train_data.drop('solved_conflict', axis=1)"
=======
   "execution_count": 4,
   "id": "82bab64a-e3e9-4737-88f8-3069d51eea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = train_data.drop('solved_conflict', axis=1)"
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 5,
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   "id": "2b0e43fd-b039-4889-a78e-95c25006ceb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
       "      <td>4f9c8bcd60318b0d1257f35ebc7c4ede9f7930e1</td>\n",
       "      <td>Die Ausbreitung des Virus sei beschränkter als...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0531b165e42997e8eecbb84d1e774c728041db8c</td>\n",
       "      <td>Zwar sei ein Anstieg der Zahlen zu verzeichnen.</td>\n",
=======
       "      <td>b9e1635a-72aa-467f-86d6-f56ef09f62c3</td>\n",
       "      <td>Gone are the days when they led the world in r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f99b5143-70d2-494a-a2f5-c68f10d09d0a</td>\n",
       "      <td>The trend is expected to reverse as soon as ne...</td>\n",
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
<<<<<<< HEAD
       "      <td>c34bac7a38d7959b0d3c340810f5d2ac3187a3ec</td>\n",
       "      <td>Der Arbeitsmarkt hat sich so zugunsten der Lei...</td>\n",
=======
       "      <td>4076639c-aa56-4202-ae0f-9d9217f8da68</td>\n",
       "      <td>But there is the specious point again.</td>\n",
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
<<<<<<< HEAD
       "      <td>3c6b7daf4e0cce25f45c8497da669c8936a66113</td>\n",
       "      <td>Es wird das PCR-Pooling mit Antigen-Schnelltes...</td>\n",
=======
       "      <td>b057c366-698e-419d-a284-9b16d835c64e</td>\n",
       "      <td>He added he wouldn’t be surprised to see a new...</td>\n",
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
<<<<<<< HEAD
       "      <td>9d241c839c8b801bdbc526cd6e20f70ecd11f341</td>\n",
       "      <td>Als er bemerkte, dass Internetbetreiber die Ge...</td>\n",
       "      <td>0</td>\n",
=======
       "      <td>a5a9645e-7850-41ba-90a2-5def725cd5b8</td>\n",
       "      <td>Not less government, you see; the same amount ...</td>\n",
       "      <td>1</td>\n",
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>795</th>\n",
       "      <td>26742376756a241814a3e089349d1c08dd267012</td>\n",
       "      <td>Der lettische Regierungschef Krisjans Karins h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>6c68576e3227cd0ae611abe6527e441c196a4e6d</td>\n",
       "      <td>Das Angiotensin-konvertierende Enzym 2 wird ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>5c2da5d7dc995638e388fa7c0a8b643bdd266a18</td>\n",
       "      <td>„In enger Abstimmung mit dem Ministerium für A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>7f2b3c069add8f1db904077337748b6c79d659be</td>\n",
       "      <td>Unter anderem sollen die Patrouillen an Land u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>c689bd94d876c250724f1e1c6bec84aabff923ea</td>\n",
       "      <td>Am Mittwoch der vergangenen Woche waren zunäch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  sentence_id  \\\n",
       "0    4f9c8bcd60318b0d1257f35ebc7c4ede9f7930e1   \n",
       "1    0531b165e42997e8eecbb84d1e774c728041db8c   \n",
       "2    c34bac7a38d7959b0d3c340810f5d2ac3187a3ec   \n",
       "3    3c6b7daf4e0cce25f45c8497da669c8936a66113   \n",
       "4    9d241c839c8b801bdbc526cd6e20f70ecd11f341   \n",
       "..                                        ...   \n",
       "795  26742376756a241814a3e089349d1c08dd267012   \n",
       "796  6c68576e3227cd0ae611abe6527e441c196a4e6d   \n",
       "797  5c2da5d7dc995638e388fa7c0a8b643bdd266a18   \n",
       "798  7f2b3c069add8f1db904077337748b6c79d659be   \n",
       "799  c689bd94d876c250724f1e1c6bec84aabff923ea   \n",
       "\n",
       "                                              sentence  label  \n",
       "0    Die Ausbreitung des Virus sei beschränkter als...      0  \n",
       "1      Zwar sei ein Anstieg der Zahlen zu verzeichnen.      0  \n",
       "2    Der Arbeitsmarkt hat sich so zugunsten der Lei...      0  \n",
       "3    Es wird das PCR-Pooling mit Antigen-Schnelltes...      0  \n",
       "4    Als er bemerkte, dass Internetbetreiber die Ge...      0  \n",
       "..                                                 ...    ...  \n",
       "795  Der lettische Regierungschef Krisjans Karins h...      0  \n",
       "796  Das Angiotensin-konvertierende Enzym 2 wird ha...      0  \n",
       "797  „In enger Abstimmung mit dem Ministerium für A...      0  \n",
       "798  Unter anderem sollen die Patrouillen an Land u...      0  \n",
       "799  Am Mittwoch der vergangenen Woche waren zunäch...      0  \n",
       "\n",
       "[800 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
=======
       "      <th>825</th>\n",
       "      <td>9a0f5eec-cc36-49b8-88eb-20ad2c056eaa</td>\n",
       "      <td>Local governments and their financing vehicles...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>73545884-adf8-480c-a8b5-e65128ba8e91</td>\n",
       "      <td>That fact alone underscores the biggest proble...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>a8825286-21a4-46c9-9410-c0e7e183d708</td>\n",
       "      <td>Presumably it had in mind those Russian offici...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>c984fc97-2604-4690-a2c0-d748703663af</td>\n",
       "      <td>From bad taxation, reckless borrowing and reck...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>1b79225e-db68-43ef-a025-544b23a6c058</td>\n",
       "      <td>Foreign Ministry spokeswoman Mariya Zakharova,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sentence_id  \\\n",
       "0    b9e1635a-72aa-467f-86d6-f56ef09f62c3   \n",
       "1    f99b5143-70d2-494a-a2f5-c68f10d09d0a   \n",
       "2    4076639c-aa56-4202-ae0f-9d9217f8da68   \n",
       "3    b057c366-698e-419d-a284-9b16d835c64e   \n",
       "4    a5a9645e-7850-41ba-90a2-5def725cd5b8   \n",
       "..                                    ...   \n",
       "825  9a0f5eec-cc36-49b8-88eb-20ad2c056eaa   \n",
       "826  73545884-adf8-480c-a8b5-e65128ba8e91   \n",
       "827  a8825286-21a4-46c9-9410-c0e7e183d708   \n",
       "828  c984fc97-2604-4690-a2c0-d748703663af   \n",
       "829  1b79225e-db68-43ef-a025-544b23a6c058   \n",
       "\n",
       "                                              sentence  label  \n",
       "0    Gone are the days when they led the world in r...      1  \n",
       "1    The trend is expected to reverse as soon as ne...      0  \n",
       "2               But there is the specious point again.      0  \n",
       "3    He added he wouldn’t be surprised to see a new...      0  \n",
       "4    Not less government, you see; the same amount ...      1  \n",
       "..                                                 ...    ...  \n",
       "825  Local governments and their financing vehicles...      1  \n",
       "826  That fact alone underscores the biggest proble...      1  \n",
       "827  Presumably it had in mind those Russian offici...      1  \n",
       "828  From bad taxation, reckless borrowing and reck...      1  \n",
       "829  Foreign Ministry spokeswoman Mariya Zakharova,...      1  \n",
       "\n",
       "[830 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 6,
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   "id": "eb5e64bf-6878-4798-909e-8cafd20d509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 7,
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   "id": "9316a84c-fbfa-4470-a6d6-7bd982b1d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_data['sentence'].tolist(), truncation=True, padding=True)\n",
    "eval_encodings = tokenizer(dev_data['sentence'].tolist(), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8410770-d13a-4171-a1ab-8649cea1a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_encodings[\"input_ids\"]\n",
    "#train_encodings[\"attention_mask\"]\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 9,
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   "id": "54d733c6-fe92-4669-be32-2d41330930c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(train_encodings['input_ids']),\n",
    "    torch.tensor(train_encodings['attention_mask']),\n",
    "    torch.tensor(train_data['label'])\n",
    ")\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(eval_encodings['input_ids']),\n",
    "    torch.tensor(eval_encodings['attention_mask']),\n",
    "    torch.tensor(dev_data['label'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 10,
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   "id": "fef0ac7b-eddf-4d72-a6e5-ed40fd5c0704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "torch.Size([157])\n",
      "torch.Size([157])\n",
=======
      "torch.Size([158])\n",
      "torch.Size([158])\n",
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][0].shape) # input_ids shape\n",
    "print(train_dataset[0][1].shape) # attention_mask shape\n",
    "print(train_dataset[0][2].shape) # train_labels_onehot shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 11,
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   "id": "e52d0654-f37c-45a9-8cf0-f0eb9394f709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-large', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 12,
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   "id": "c5047e6e-4428-4172-bcf1-582d78d540c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer parameters\n",
<<<<<<< HEAD
    "epochs = 3"
=======
    "epochs = 3\n",
    "learning_rate=5e-5"
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 13,
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   "id": "561d3b8a-6e2e-4e74-8d5b-365031776a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
<<<<<<< HEAD
    "    num_train_epochs=3,  # Train for fewer epochs\n",
    "    per_device_train_batch_size=16,  # Increase batch size for faster processing\n",
    "    per_device_eval_batch_size=16,  # Keep evaluation batch size consistent with training\n",
    "    warmup_steps=500,  # Reduce warmup steps\n",
    "    weight_decay=0.01,  # Keep weight decay as it is\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,  # Log less frequently for faster training\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=200,  # Evaluate less frequently for faster training\n",
    "    learning_rate=5e-5,  # Keep learning rate as it is\n",
=======
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=50,\n",
    "    learning_rate=learning_rate,\n",
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "id": "493e86e5-a63f-40dc-b6bb-09e3bf48a3c2",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 14,
   "id": "493e86e5-a63f-40dc-b6bb-09e3bf48a3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\Documents\\py_interpreter2\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   "source": [
    "# Define the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=lambda data: {'input_ids': torch.stack([item[0] for item in data]),\n",
    "                                'attention_mask': torch.stack([item[1] for item in data]),\n",
    "                                'labels': torch.stack([item[2] for item in data])},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 15,
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   "id": "96eb11d6-0c5c-4d85-b10d-0e2a028b0f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca03ece810b43cc8042d90c0e949877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
=======
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 50:31, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.654100</td>\n",
       "      <td>0.752289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.585300</td>\n",
       "      <td>0.804733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.543400</td>\n",
       "      <td>0.906971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.560200</td>\n",
       "      <td>0.755962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.653800</td>\n",
       "      <td>1.046434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6898, 'grad_norm': 8.063957214355469, 'learning_rate': 1e-05, 'epoch': 2.0}\n",
      "{'train_runtime': 4488.6922, 'train_samples_per_second': 0.535, 'train_steps_per_second': 0.033, 'train_loss': 0.6680028279622395, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=0.6680028279622395, metrics={'train_runtime': 4488.6922, 'train_samples_per_second': 0.535, 'train_steps_per_second': 0.033, 'total_flos': 685843237699200.0, 'train_loss': 0.6680028279622395, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
=======
     "data": {
      "text/plain": [
       "TrainOutput(global_step=260, training_loss=0.5948242315879235, metrics={'train_runtime': 3042.9784, 'train_samples_per_second': 1.364, 'train_steps_per_second': 0.085, 'total_flos': 1193491005730800.0, 'train_loss': 0.5948242315879235, 'epoch': 5.0})"
      ]
     },
     "execution_count": 15,
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# epoch 4 / 50 = 200\t0.538800\t0.644553"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": null,
   "id": "b94836ea-f1b4-4a3c-9a28-ff59e88400fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   "id": "d7a43a6c-c16c-4727-a3e0-535b08399f4e",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "model.save_pretrained(\"./model\")"
=======
    "#model.save_pretrained(\"./model\")"
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be77525e-b65e-4001-9cf2-e944bf62f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = XLMRobertaForSequenceClassification.from_pretrained(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 18,
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   "id": "0ed6e01f-b6c1-4fbc-b6eb-08fb20e1984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
<<<<<<< HEAD
    "test_data = pd.read_csv(\"data/subtask-2-english/dev_test_en.tsv\", sep='\\t')  # Update with your dev data file\n",
=======
    "test_data = pd.read_csv(\"data/subtask-2-german/dev_test_de.tsv\", sep='\\t')  # Update with your dev data file\n",
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
    "test_data['label'] = test_data['label'].map(label_map)\n",
    "test_encodings = tokenizer(test_data['sentence'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(test_encodings['input_ids']),\n",
    "    torch.tensor(test_encodings['attention_mask']),\n",
    "    torch.tensor(test_data['label'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 19,
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   "id": "e27e6a25-370d-46ca-a31a-7ecaa349c6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542b692b314b4b6d83ac1b1ad4e15baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
=======
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer.predict(test_dataset)\n",
    "pred_labels = preds.predictions.argmax(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 20,
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   "id": "43978ae1-955e-4775-8566-3b654114c453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
=======
      "[1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1\n",
      " 0 0 1 1 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 0 0 1\n",
      " 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 0\n",
      " 1 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0 1\n",
      " 0 0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 0 1]\n"
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
     ]
    }
   ],
   "source": [
    "print(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 21,
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   "id": "150f12f8-f0cd-4a7d-aa88-d18edb5c33f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Accuracy for RoBERTa: 0.5967078189300411\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         OBJ       0.55      0.89      0.68       116\n",
      "        SUBJ       0.76      0.33      0.46       127\n",
      "\n",
      "    accuracy                           0.60       243\n",
      "   macro avg       0.66      0.61      0.57       243\n",
      "weighted avg       0.66      0.60      0.56       243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for ChatGPT-4: 0.4773662551440329\n",
      "Classification Report for ChatGPT-4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         OBJ       0.48      1.00      0.65       116\n",
      "        SUBJ       1.00      0.00      0.00       127\n",
      "\n",
      "    accuracy                           0.48       243\n",
      "   macro avg       0.74      0.50      0.32       243\n",
      "weighted avg       0.75      0.48      0.31       243\n",
=======
      "Accuracy for RoBERTa: 0.7901234567901234\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         OBJ       0.85      0.68      0.76       116\n",
      "        SUBJ       0.75      0.89      0.82       127\n",
      "\n",
      "    accuracy                           0.79       243\n",
      "   macro avg       0.80      0.79      0.79       243\n",
      "weighted avg       0.80      0.79      0.79       243\n",
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the true labels to integers\n",
    "\n",
    "# Compute the accuracy and classification report\n",
    "accuracy = accuracy_score(test_data['label'], pred_labels)\n",
    "class_report = classification_report(test_data['label'], pred_labels, target_names=['OBJ', 'SUBJ'])\n",
    "\n",
    "print(f\"Accuracy for RoBERTa: {accuracy}\")\n",
<<<<<<< HEAD
    "print(f\"Classification Report:\\n{class_report}\")\n",
    "\n",
    "\n",
    "# Now, let's use ChatGPT-4 for evaluation\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Load the ChatGPT-4 text classification pipeline\n",
    "chatgpt4_classifier = pipeline(\"text-classification\", model=\"EleutherAI/gpt-neo-2.7B\")\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv(\"data/subtask-2-english/dev_test_en.tsv\", sep='\\t')\n",
    "\n",
    "# Mapping label strings to integers\n",
    "label_map = {\"OBJ\": 0, \"SUBJ\": 1}\n",
    "test_data['label'] = test_data['label'].map(label_map)\n",
    "\n",
    "# Make predictions using ChatGPT-4\n",
    "chatgpt4_predictions = chatgpt4_classifier(test_data['sentence'].tolist())\n",
    "\n",
    "# Extract predicted labels from ChatGPT-4 predictions\n",
    "chatgpt4_pred_labels = [1 if pred[\"label\"] == \"SUBJ\" else 0 for pred in chatgpt4_predictions]\n",
    "\n",
    "# Compute accuracy and classification report for ChatGPT-4\n",
    "chatgpt4_accuracy = accuracy_score(test_data['label'], chatgpt4_pred_labels)\n",
    "chatgpt4_class_report = classification_report(test_data['label'], chatgpt4_pred_labels, target_names=['OBJ', 'SUBJ'], zero_division=1)\n",
    "\n",
    "print(f\"Accuracy for ChatGPT-4: {chatgpt4_accuracy}\")\n",
    "print(f\"Classification Report for ChatGPT-4:\\n{chatgpt4_class_report}\")"
=======
    "print(f\"Classification Report:\\n{class_report}\")"
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67dacc59-1c15-4158-9d99-edd69d90bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs 3 eval steps 50 - acc 0.58 - OBJ 0.54, SUBJ 0.81\n",
    "# epochs 10 eval steps 60 - BROKE\n",
    "# epochs 2 eval steps 50 - acc 0.61 - OBJ 0.56, SUBJ 0.71 - f1 0.66 - 0.54\n",
    "# epochs 4 eval steps 50 - acc 0.70 - OBJ 0.67, SUBJ 0.74 - f1 0.70 - 0.70\n",
    "# epochs 5 eval steps 50 - acc 0.79 - OBJ 0.85, SUBJ 0.75 - f1 0.76 - 0.82"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.12.1"
=======
   "version": "3.11.9"
>>>>>>> 6a75ae8c729928ca5da60aff90ff3923fecf48c7
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
