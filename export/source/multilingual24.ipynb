{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c4db13-918e-46cf-a8d5-89285ad62b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bambo\\PycharmProjects\\kuba\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Import STOPWORDS from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string, re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c35f562f-c314-4a15-b279-f5b0b3ab3725",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw = pd.read_csv(\"data/subtask-2-multilingual/ml_only_2024_languages/train_ml_only_2024_languages.tsv\",sep='\\t')\n",
    "#dev_data = pd.read_csv(\"data/subtask-2-multilingual/ml_only_2024_languages/dev_ml_only_2024_languages.tsv\", sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c53ea713-6960-4720-8fb9-c0190c29d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data_raw.sample(n=1500)\n",
    "dev_data = train_data_raw.sample(n=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "453ce330-db05-4ad1-b504-01003af28b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2053    0\n",
      "589     0\n",
      "3941    0\n",
      "179     0\n",
      "3604    0\n",
      "       ..\n",
      "3331    1\n",
      "232     0\n",
      "1305    1\n",
      "3427    1\n",
      "3518    0\n",
      "Name: label, Length: 1500, dtype: int64\n",
      "1337    0\n",
      "3183    0\n",
      "1168    0\n",
      "4337    0\n",
      "4350    1\n",
      "       ..\n",
      "3114    0\n",
      "3276    0\n",
      "189     0\n",
      "161     1\n",
      "1361    1\n",
      "Name: label, Length: 300, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mapping label strings to integers\n",
    "label_map = {\"OBJ\": 0, \"SUBJ\": 1}\n",
    "train_data['label'] = train_data['label'].map(label_map)\n",
    "print(train_data['label'])\n",
    "\n",
    "dev_data['label'] = dev_data['label'].map(label_map)\n",
    "print(dev_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82bab64a-e3e9-4737-88f8-3069d51eea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = train_data.drop('solved_conflict', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b0e43fd-b039-4889-a78e-95c25006ceb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>183b50f29309276f125e605f0c83fc1e6a7bb67f</td>\n",
       "      <td>Der andere Angeklagte bekundete, er könne sich...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>AFP_29-eurl_02_003</td>\n",
       "      <td>بالتزامن مع ذلك تواجه فرنسا اتهامات قضائية بال...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941</th>\n",
       "      <td>d5773929-3805-44a6-bd17-299c1a1c36ad</td>\n",
       "      <td>Ieri i test positivi erano stati 7.925, i mort...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>MIS_2852-curl_04_003</td>\n",
       "      <td>وتابع: \"يمكننا القيام بذلك لأن جهازنا الصحي هو...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3604</th>\n",
       "      <td>1c3faba9-0fa3-4c13-bdd1-9f3cc1e333d8</td>\n",
       "      <td>Venerdì — mentre veniva «processata» nei forum...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>a37add47-58f6-4da6-9d79-93a783eca9d3</td>\n",
       "      <td>Come ripeto ormai da anni le soluzioni ci sono...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>MIS_561-curl_02_022</td>\n",
       "      <td>وتقدم السودان بعد الثورة على البشير إلى المرتب...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>9ebd51e3-8f5a-4174-938f-1efdf3bfe85d</td>\n",
       "      <td>The reason for the lack of any actual ‘levelli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>5c144c6e-2295-4cc6-86f4-82b60b7327d6</td>\n",
       "      <td>Anche dal consulente più impensabile: Walter R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>24a6e731-fd52-46c7-8ce2-9ebf4fef959c</td>\n",
       "      <td>Nuovo picco di ricoverati Covid in Umbria</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   sentence_id  \\\n",
       "2053  183b50f29309276f125e605f0c83fc1e6a7bb67f   \n",
       "589                         AFP_29-eurl_02_003   \n",
       "3941      d5773929-3805-44a6-bd17-299c1a1c36ad   \n",
       "179                       MIS_2852-curl_04_003   \n",
       "3604      1c3faba9-0fa3-4c13-bdd1-9f3cc1e333d8   \n",
       "...                                        ...   \n",
       "3331      a37add47-58f6-4da6-9d79-93a783eca9d3   \n",
       "232                        MIS_561-curl_02_022   \n",
       "1305      9ebd51e3-8f5a-4174-938f-1efdf3bfe85d   \n",
       "3427      5c144c6e-2295-4cc6-86f4-82b60b7327d6   \n",
       "3518      24a6e731-fd52-46c7-8ce2-9ebf4fef959c   \n",
       "\n",
       "                                               sentence  label  \n",
       "2053  Der andere Angeklagte bekundete, er könne sich...      0  \n",
       "589   بالتزامن مع ذلك تواجه فرنسا اتهامات قضائية بال...      0  \n",
       "3941  Ieri i test positivi erano stati 7.925, i mort...      0  \n",
       "179   وتابع: \"يمكننا القيام بذلك لأن جهازنا الصحي هو...      0  \n",
       "3604  Venerdì — mentre veniva «processata» nei forum...      0  \n",
       "...                                                 ...    ...  \n",
       "3331  Come ripeto ormai da anni le soluzioni ci sono...      1  \n",
       "232   وتقدم السودان بعد الثورة على البشير إلى المرتب...      0  \n",
       "1305  The reason for the lack of any actual ‘levelli...      1  \n",
       "3427  Anche dal consulente più impensabile: Walter R...      1  \n",
       "3518          Nuovo picco di ricoverati Covid in Umbria      0  \n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5e64bf-6878-4798-909e-8cafd20d509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9316a84c-fbfa-4470-a6d6-7bd982b1d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_data['sentence'].tolist(), truncation=True, padding=True)\n",
    "eval_encodings = tokenizer(dev_data['sentence'].tolist(), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8410770-d13a-4171-a1ab-8649cea1a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_encodings[\"input_ids\"]\n",
    "#train_encodings[\"attention_mask\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54d733c6-fe92-4669-be32-2d41330930c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(train_encodings['input_ids']),\n",
    "    torch.tensor(train_encodings['attention_mask']),\n",
    "    torch.tensor(train_data['label'].to_numpy())\n",
    ")\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(eval_encodings['input_ids']),\n",
    "    torch.tensor(eval_encodings['attention_mask']),\n",
    "    torch.tensor(dev_data['label'].to_numpy())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fef0ac7b-eddf-4d72-a6e5-ed40fd5c0704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([197])\n",
      "torch.Size([197])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][0].shape) # input_ids shape\n",
    "print(train_dataset[0][1].shape) # attention_mask shape\n",
    "print(train_dataset[0][2].shape) # train_labels_onehot shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e52d0654-f37c-45a9-8cf0-f0eb9394f709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-large', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc35ab52-6ca6-4384-a211-736850a725fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "device\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5047e6e-4428-4172-bcf1-582d78d540c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer parameters\n",
    "epochs = 4\n",
    "learning_rate=5e-5 # default 5e-5\n",
    "warmup_steps = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "561d3b8a-6e2e-4e74-8d5b-365031776a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=warmup_steps,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=25,\n",
    "    learning_rate=learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "493e86e5-a63f-40dc-b6bb-09e3bf48a3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=lambda data: {'input_ids': torch.stack([item[0] for item in data]),\n",
    "                                'attention_mask': torch.stack([item[1] for item in data]),\n",
    "                                'labels': torch.stack([item[2] for item in data])},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96eb11d6-0c5c-4d85-b10d-0e2a028b0f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='376' max='376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [376/376 49:35, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.692700</td>\n",
       "      <td>0.644363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.640200</td>\n",
       "      <td>0.589586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.606900</td>\n",
       "      <td>0.584591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.625500</td>\n",
       "      <td>0.591560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.603400</td>\n",
       "      <td>0.575733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.658100</td>\n",
       "      <td>0.568187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.520400</td>\n",
       "      <td>0.527490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.502400</td>\n",
       "      <td>0.460873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.501400</td>\n",
       "      <td>0.499050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.630100</td>\n",
       "      <td>0.584781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.517800</td>\n",
       "      <td>0.453422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.473600</td>\n",
       "      <td>0.473316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.595200</td>\n",
       "      <td>0.457944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.446800</td>\n",
       "      <td>0.477383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.499800</td>\n",
       "      <td>0.441935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=376, training_loss=0.5701390454109679, metrics={'train_runtime': 2976.9405, 'train_samples_per_second': 2.015, 'train_steps_per_second': 0.126, 'total_flos': 2151450920808000.0, 'train_loss': 0.5701390454109679, 'epoch': 4.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# epoch 4 / 50 = 200\t0.538800\t0.644553"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94836ea-f1b4-4a3c-9a28-ff59e88400fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7a43a6c-c16c-4727-a3e0-535b08399f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_pretrained(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be77525e-b65e-4001-9cf2-e944bf62f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = XLMRobertaForSequenceClassification.from_pretrained(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ed6e01f-b6c1-4fbc-b6eb-08fb20e1984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_data = pd.read_csv(\"data/subtask-2-multilingual/ml_only_2024_languages/dev_test_ml_only_2024_languages.tsv\", sep='\\t')  # Update with your dev data file\n",
    "test_data['label'] = test_data['label'].map(label_map)\n",
    "test_encodings = tokenizer(test_data['sentence'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(test_encodings['input_ids']),\n",
    "    torch.tensor(test_encodings['attention_mask']),\n",
    "    torch.tensor(test_data['label'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e27e6a25-370d-46ca-a31a-7ecaa349c6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer.predict(test_dataset)\n",
    "pred_labels = preds.predictions.argmax(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43978ae1-955e-4775-8566-3b654114c453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 0\n",
      " 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1\n",
      " 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0\n",
      " 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 1\n",
      " 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1\n",
      " 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0\n",
      " 1 0 1 1 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1\n",
      " 0 0 1 0 0 1 1 1 1 1 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1\n",
      " 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "150f12f8-f0cd-4a7d-aa88-d18edb5c33f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for RoBERTa: 0.765\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         OBJ       0.79      0.72      0.75       200\n",
      "        SUBJ       0.74      0.81      0.78       200\n",
      "\n",
      "    accuracy                           0.77       400\n",
      "   macro avg       0.77      0.77      0.76       400\n",
      "weighted avg       0.77      0.77      0.76       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the true labels to integers\n",
    "\n",
    "# Compute the accuracy and classification report\n",
    "accuracy = accuracy_score(test_data['label'], pred_labels)\n",
    "class_report = classification_report(test_data['label'], pred_labels, target_names=['OBJ', 'SUBJ'])\n",
    "\n",
    "print(f\"Accuracy for RoBERTa: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{class_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67dacc59-1c15-4158-9d99-edd69d90bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate 5e-5\n",
    "# epochs 3 - acc 0.61 - OBJ 0.56, SUBJ 0.71 - f1 0.66 - 0.54"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
