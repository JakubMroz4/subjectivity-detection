{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c4db13-918e-46cf-a8d5-89285ad62b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\Documents\\py_interpreter2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import string, re\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c35f562f-c314-4a15-b279-f5b0b3ab3725",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/subtask-2-bulgarian/train_bg.tsv\",sep='\\t')\n",
    "dev_data = pd.read_csv(\"data/subtask-2-bulgarian/dev_bg.tsv\", sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "453ce330-db05-4ad1-b504-01003af28b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      1\n",
      "      ..\n",
      "689    1\n",
      "690    0\n",
      "691    0\n",
      "692    1\n",
      "693    1\n",
      "Name: label, Length: 694, dtype: int64\n",
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "101    0\n",
      "102    0\n",
      "103    0\n",
      "104    1\n",
      "105    1\n",
      "Name: label, Length: 106, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mapping label strings to integers\n",
    "label_map = {\"OBJ\": 0, \"SUBJ\": 1}\n",
    "train_data['label'] = train_data['label'].map(label_map)\n",
    "print(train_data['label'])\n",
    "\n",
    "dev_data['label'] = dev_data['label'].map(label_map)\n",
    "print(dev_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82bab64a-e3e9-4737-88f8-3069d51eea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = train_data.drop('solved_conflict', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b0e43fd-b039-4889-a78e-95c25006ceb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b678f74b-3981-4ad9-93b3-4c549605a02c</td>\n",
       "      <td>Учителите, за които цяла България разбра, са С...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea65624a-da34-4bc4-8085-edb93d2e30e1</td>\n",
       "      <td>А ако намерите каска е още по-добре.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fd709ed2-8c81-4130-b2a3-857083eb4821</td>\n",
       "      <td>През октомври 1994г. учените от ,,Air Force\" у...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1cfc5cf2-ebd2-4db8-86ed-38673b2858fc</td>\n",
       "      <td>Аз обаче вече бях обещала, че ще летя до Алжир...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a56a980c-2bdf-4da5-8b1f-e8cef1e4305c</td>\n",
       "      <td>Ама знаете ли защо те си купиха тировете обрат...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>51ed7539-8d43-42d8-9e67-80c55f89195d</td>\n",
       "      <td>Чувствата силно ще се обезценят и само лъжлива...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>1458a621-510e-421b-ad33-a4f7b8991f32</td>\n",
       "      <td>Как да помогна на тези хора, които все повече ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>750ece90-13b4-4bae-b41f-0867772b8a35</td>\n",
       "      <td>Ще има обаче опит за покушение срещу Тръмп, до...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>7f1a9eff-a320-42ae-946b-356b1f011583</td>\n",
       "      <td>Събудената мощ на духа на българина е голяма.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>3ade5d3a-cbce-45c0-b7fd-bd5d3760b91f</td>\n",
       "      <td>Девраха Баба е мъдрец и предсказател прославил...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>694 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sentence_id  \\\n",
       "0    b678f74b-3981-4ad9-93b3-4c549605a02c   \n",
       "1    ea65624a-da34-4bc4-8085-edb93d2e30e1   \n",
       "2    fd709ed2-8c81-4130-b2a3-857083eb4821   \n",
       "3    1cfc5cf2-ebd2-4db8-86ed-38673b2858fc   \n",
       "4    a56a980c-2bdf-4da5-8b1f-e8cef1e4305c   \n",
       "..                                    ...   \n",
       "689  51ed7539-8d43-42d8-9e67-80c55f89195d   \n",
       "690  1458a621-510e-421b-ad33-a4f7b8991f32   \n",
       "691  750ece90-13b4-4bae-b41f-0867772b8a35   \n",
       "692  7f1a9eff-a320-42ae-946b-356b1f011583   \n",
       "693  3ade5d3a-cbce-45c0-b7fd-bd5d3760b91f   \n",
       "\n",
       "                                              sentence  label  \n",
       "0    Учителите, за които цяла България разбра, са С...      0  \n",
       "1                 А ако намерите каска е още по-добре.      1  \n",
       "2    През октомври 1994г. учените от ,,Air Force\" у...      0  \n",
       "3    Аз обаче вече бях обещала, че ще летя до Алжир...      0  \n",
       "4    Ама знаете ли защо те си купиха тировете обрат...      1  \n",
       "..                                                 ...    ...  \n",
       "689  Чувствата силно ще се обезценят и само лъжлива...      1  \n",
       "690  Как да помогна на тези хора, които все повече ...      0  \n",
       "691  Ще има обаче опит за покушение срещу Тръмп, до...      0  \n",
       "692      Събудената мощ на духа на българина е голяма.      1  \n",
       "693  Девраха Баба е мъдрец и предсказател прославил...      1  \n",
       "\n",
       "[694 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb5e64bf-6878-4798-909e-8cafd20d509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9316a84c-fbfa-4470-a6d6-7bd982b1d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_data['sentence'].tolist(), truncation=True, padding=True)\n",
    "eval_encodings = tokenizer(dev_data['sentence'].tolist(), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8410770-d13a-4171-a1ab-8649cea1a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_encodings[\"input_ids\"]\n",
    "#train_encodings[\"attention_mask\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54d733c6-fe92-4669-be32-2d41330930c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(train_encodings['input_ids']),\n",
    "    torch.tensor(train_encodings['attention_mask']),\n",
    "    torch.tensor(train_data['label'])\n",
    ")\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(eval_encodings['input_ids']),\n",
    "    torch.tensor(eval_encodings['attention_mask']),\n",
    "    torch.tensor(dev_data['label'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fef0ac7b-eddf-4d72-a6e5-ed40fd5c0704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][0].shape) # input_ids shape\n",
    "print(train_dataset[0][1].shape) # attention_mask shape\n",
    "print(train_dataset[0][2].shape) # train_labels_onehot shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e52d0654-f37c-45a9-8cf0-f0eb9394f709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-large', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b39a09-9ff7-44ef-abab-7a8c1ed83184",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5047e6e-4428-4172-bcf1-582d78d540c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer parameters\n",
    "epochs = 3\n",
    "learning_rate=5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "561d3b8a-6e2e-4e74-8d5b-365031776a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=50,\n",
    "    learning_rate=learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "493e86e5-a63f-40dc-b6bb-09e3bf48a3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kuba\\Documents\\py_interpreter2\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=lambda data: {'input_ids': torch.stack([item[0] for item in data]),\n",
    "                                'attention_mask': torch.stack([item[1] for item in data]),\n",
    "                                'labels': torch.stack([item[2] for item in data])},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb11d6-0c5c-4d85-b10d-0e2a028b0f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  3/132 02:12 < 4:45:04, 0.01 it/s, Epoch 0.05/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# epoch 4 / 50 = 200\t0.538800\t0.644553"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94836ea-f1b4-4a3c-9a28-ff59e88400fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a43a6c-c16c-4727-a3e0-535b08399f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_pretrained(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be77525e-b65e-4001-9cf2-e944bf62f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = XLMRobertaForSequenceClassification.from_pretrained(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed6e01f-b6c1-4fbc-b6eb-08fb20e1984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_data = pd.read_csv(\"data/subtask-2-bulgarian/dev_test_bg.tsv\", sep='\\t')  # Update with your dev data file\n",
    "test_data['label'] = test_data['label'].map(label_map)\n",
    "test_encodings = tokenizer(test_data['sentence'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(test_encodings['input_ids']),\n",
    "    torch.tensor(test_encodings['attention_mask']),\n",
    "    torch.tensor(test_data['label'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27e6a25-370d-46ca-a31a-7ecaa349c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(test_dataset)\n",
    "pred_labels = preds.predictions.argmax(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43978ae1-955e-4775-8566-3b654114c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150f12f8-f0cd-4a7d-aa88-d18edb5c33f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the true labels to integers\n",
    "\n",
    "# Compute the accuracy and classification report\n",
    "accuracy = accuracy_score(test_data['label'], pred_labels)\n",
    "class_report = classification_report(test_data['label'], pred_labels, target_names=['OBJ', 'SUBJ'])\n",
    "\n",
    "print(f\"Accuracy for RoBERTa: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{class_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dacc59-1c15-4158-9d99-edd69d90bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs 2 eval steps 50 - acc 0.61 - OBJ 0.56, SUBJ 0.71 - f1 0.66 - 0.54"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
